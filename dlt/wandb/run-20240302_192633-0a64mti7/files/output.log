


Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 104/104 [00:05<00:00, 18.99it/s, loss=nan, lr=2.08e-6, step=104]
############################################################################################################
step:  800
batch:  tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
############################################################################################################
############################################################################################################
step:  600
batch:  tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0') tensor(nan, device='cuda:0')
Epoch 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 104/104 [00:05<00:00, 18.99it/s, loss=nan, lr=2.08e-6, step=104]Traceback (most recent call last):
  File "/home/sehwan/MIIL/CAL-Refactoring/dlt/main.py", line 181, in <module>
    main()
  File "/home/sehwan/MIIL/CAL-Refactoring/dlt/main.py", line 54, in main
    TrainLoopCAL(accelerator=accelerator, model=model, diffusion=noise_scheduler,
  File "/home/sehwan/MIIL/CAL-Refactoring/dlt/trainers/cal_trainer.py", line 129, in train
    self.CAL_train(epoch, self.diffusion_mode)
  File "/home/sehwan/MIIL/CAL-Refactoring/dlt/trainers/cal_trainer.py", line 243, in CAL_train
    train_pred_geometry_1000 = sample_from_model(batch, self.model, device, self.diffusion, geometry_scale, self.diffusion_mode, self.image_pred_ox)
  File "/home/sehwan/MIIL/CAL-Refactoring/dlt/trainers/cal_trainer_func.py", line 32, in sample_from_model
    epsilon_pred = model(batch, noisy_batch, timesteps=t)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sehwan/MIIL/CAL-Refactoring/dlt/models/CAL.py", line 134, in forward
    output = self.seqTransEncoder(xseq, src_key_padding_mask = key_padding_mask)[1:] #time step embedding 제외
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 391, in forward
    output = mod(output, src_mask=mask, is_causal=is_causal, src_key_padding_mask=src_key_padding_mask_for_layers)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 714, in forward
    x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal))
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/transformer.py", line 722, in _sa_block
    x = self.self_attn(x, x, x,
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1241, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/home/sehwan/anaconda3/envs/CAL/lib/python3.9/site-packages/torch/nn/functional.py", line 5479, in multi_head_attention_forward
    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
KeyboardInterrupt